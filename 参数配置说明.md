# `fit_attacker.py` 参数与命令说明

本文介绍使用 `fit_attacker.py` 运行语言混淆攻击时常用的参数含义、推荐设置方式，以及基于 `attack_configs/whisper/univ_lang_fit.yaml` 的典型命令示例。

## 一、命令示例
下面的命令以 LibriSpeech 数据集为例，覆盖 YAML 中的默认设置，训练中文攻击扰动、在英文数据上验证，并使用 Whisper-small 模型：

```bash
python fit_attacker.py attack_configs/whisper/univ_lang_fit.yaml \
    --root=/root/autodl-tmp/whisper_attack_Lang-Confusion \
    --dataset_prepare_fct=robust_speech.data.librispeech.prepare_librispeech \
    --data_folder=/root/autodl-tmp/prepend_acoustic_attack/data/librispeech/LibriSpeech \
    --csv_folder=/root/autodl-tmp/prepend_acoustic_attack/data/librispeech/LibriSpeech/csv \
    --train_csv=/root/autodl-tmp/prepend_acoustic_attack/data/librispeech/LibriSpeech/csv/fit.csv \
    --test_csv=/root/autodl-tmp/prepend_acoustic_attack/data/librispeech/LibriSpeech/csv/test-clean.csv \
    --lang_attack=zh --lang_CV=en \
    --model_label=small \
    --load_audio=True --batch_size=32 --nb_iter=5 --eps=0.005 --eps_item=0.001 \
    --rel_eps_iter=0.01 --epochs=10 --success_every=100 --seed=1101
```

## 二、参数覆盖规则
- CLI 参数会覆盖 YAML 中的同名键，并据此重新推导衍生字段（如 `model_name`、`output_folder`）。
- 未在命令行中显式指定的键继续使用 YAML 默认值（如 `targeted_for_language: true`、`attack_class`、`sample_rate` 等）。
- 路径相关字段最好成对覆盖，避免混用默认 CommonVoice 路径和自定义 LibriSpeech 路径。

## 三、关键参数解读与设置建议
### 1. 路径与数据准备
- `root`：实验根目录，用于存放 tokenizer、输出和日志。应指向可读写磁盘路径。
- `dataset_prepare_fct`：数据预处理函数。常见取值：
  - `robust_speech.data.common_voice.prepare_common_voice`（默认，适合 CommonVoice）。
  - `robust_speech.data.librispeech.prepare_librispeech`（适合 LibriSpeech）。
- `data_folder`/`csv_folder`：原始音频与 CSV 的位置，需与所选数据集对应。
- `train_csv`/`test_csv`：训练/验证列表。CSV 必含 `ID`、`duration`、`wav`、`wrd`，若做语言攻击还需 `lang` 列。
- `skip_prep`：为 `True` 时跳过特征预处理，数据必须已准备完毕；若首次运行建议设为 `False` 让脚本生成所需文件。

### 2. 攻击与优化相关
- `lang_attack`：目标扰动语种（如 `zh` 表示让模型误识中文）。
- `lang_CV`：验证集语种；同时影响 CommonVoice 下载/选择语言。
- `eps`/`eps_item`：扰动全局与单样本的 L∞ 范数上界，数值越大攻击越强但失真更明显。
- `nb_iter`：单轮 PGD 迭代步数，>1 时更精细但更耗时。
- `rel_eps_iter`：每步相对步长，通常为 `eps` 的 1%~5%。
- `epochs`：训练轮数。若只想验证流程可设为 5~10；正式训练可提高到几十或上百。
- `batch_size`：训练批大小，受显存限制影响；通用 GPU 可从 8/16 起尝试。
- `success_every`：每隔多少步检查一次攻击成功率，用于早停或记录。
- `avoid_if_longer_than`：过滤过长语音，默认 24 秒，降低 OOM 风险。

### 3. 模型与解码
- `model_label`：Whisper 规模，需与 `model_configs/<model_label>.yaml` 匹配（如 `tiny`、`base`、`small` 等）。
- `model_name`/`source_model_name`：由 `model_label` 推导，指向实际 HuggingFace 模型名。
- `tokenizer_name`：建议保留 `multilingual` 以匹配多语言场景。
- 采样率与声学参数（`sample_rate`、`n_fft`、`n_mels`）通常无需修改，除非模型配置要求。

### 4. 输出与日志
- `output_folder`：默认 `root/attacks/<attack_name>/<lang_attack>/<source_model_name>/<seed>`，包含模型参数、对抗样本和日志。
- `log`：训练日志文件路径。若需调试可追加 `--debug`（若脚本支持）或调整 `logger` 配置。
- `save_audio`/`save_audio_path`：是否保存生成的对抗音频及其目录。

### 5. 测试集 split 逻辑
- `test_splits` 与 `test_csv` 会成对 zip：`["test_clean", "test_other"]` 与 `[clean.csv, other.csv]` 会构建两个独立的测试集，评估时分别调用 `evaluate`，不会把所有样本合并后一次性跑完。
- 若只传入单个字符串（例如 `--test_csv=...`），脚本会在内部转换为单元素列表，避免被按字符拆分导致的非法路径错误。

## 四、推荐配置流程
1. **准备数据**：确保 `data_folder` 下有音频，`csv_folder` 下有训练/测试 CSV，并确认字段完整。
2. **设置根路径**：用 `--root` 指向可写目录，避免覆盖默认 placeholder。
3. **选择模型**：根据显存与速度选定 `--model_label`，并确认对应权重可下载或已缓存。
4. **调整攻击强度**：先用较小 `eps`/`nb_iter` 试跑，再逐步提高；留意音质与成功率。
5. **控制训练成本**：通过 `--epochs` 和 `--batch_size` 平衡时间与效果；必要时缩短数据集或使用子集 CSV。
6. **验证与保存**：查看 `log.txt`、`wer.txt` 以及保存的对抗音频，确认攻击表现。

## 五、排查与建议
- 若脚本报找不到路径或 CSV，优先检查 `--root`、`--data_folder`、`--csv_folder` 以及 CSV 列名。
- 若显存不足，可减小 `batch_size` 或缩短音频时长（调整 `avoid_if_longer_than`）。
- 若训练过慢，降低 `nb_iter`、`epochs` 或使用较小模型（如 `tiny`/`base`）。

通过以上说明，可快速根据数据集与资源约束调整参数，确保命令顺利运行并得到期望的攻击效果。

## 六、与论文默认设置的对照
- **论文提供的通用扰动基线**（用户描述）：SNR 40dB、70 条训练句子、2000 个 epoch、每条输入只走 1 步 PGD，学习率约为 `0.001 * eps`。
- **仓库当前 YAML 默认**：
  - `eps: 0.005`、`eps_item: 0.001`、`rel_eps_iter: 0.01`、`nb_iter: 1`，与论文“一步 PGD、学习率≈0.01*eps_item”在迭代步数上对齐，但学习率与 SNR 对应关系需自己换算。【F:attack_configs/whisper/univ_lang_fit.yaml†L11-L34】
  - `epochs: 10000`，默认远高于论文的 2000 轮，适合占用更长训练时间；若想复现论文设置可将命令行 `--epochs` 改为 2000。【F:attack_configs/whisper/univ_lang_fit.yaml†L17-L23】
  - 默认数据集指向 Common Voice (`dataset_prepare_fct: prepare_common_voice`，`data_folder: <root>/data/CommonVoice/<lang_CV>`)，并假定存在 `fit.csv`/`test-clean.csv`。若要严格对齐“70 条训练句子”，需要在生成训练 CSV 时额外下采样或在 `csv_make.py` 中使用自定义采样参数。【F:attack_configs/whisper/univ_lang_fit.yaml†L55-L84】【F:csv_make.py†L1-L80】
- **如何对齐论文描述**：
  1. 用 CSV 下采样到 70 条训练样本，并在命令行传入对应的 `--train_csv`。
  2. 命令行设置 `--epochs=2000 --nb_iter=1 --eps=0.005 --eps_item=0.001 --rel_eps_iter=0.01`（或根据需要调整 `eps` 以匹配 40dB 目标），学习率可通过 `rel_eps_iter` 和 `eps_item` 共同决定。
  3. 若需要固定 SNR，可改用 PGD 的 SNR 约束配置或在攻击类中增加 SNR 控制，当前 YAML 默认未显式设置 SNR，因此需自行换算 `eps`。
